{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "id": "tR9wy9jki5p7",
        "gather": {
          "logged": 1737426468713
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio transformers datasets matplotlib scikit-learn\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: torch in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (2.4.1)\nRequirement already satisfied: torchvision in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (0.19.1)\nRequirement already satisfied: torchaudio in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (2.4.1)\nRequirement already satisfied: transformers in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (4.36.2)\nRequirement already satisfied: datasets in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (2.16.1)\nRequirement already satisfied: matplotlib in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (3.6.3)\nRequirement already satisfied: scikit-learn in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.5.1)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (12.1.3.1)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (3.0.0)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (2.20.5)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (12.1.0.106)\nRequirement already satisfied: jinja2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (2023.10.0)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (10.3.2.106)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: networkx in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (3.15.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: typing-extensions>=4.8.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (11.4.5.107)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (11.0.2.54)\nRequirement already satisfied: sympy in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch) (1.13.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.68)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torchvision) (9.2.0)\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torchvision) (1.23.5)\nRequirement already satisfied: tqdm>=4.27 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: regex!=2019.12.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (2024.7.24)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: safetensors>=0.3.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (0.24.5)\nRequirement already satisfied: requests in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: pandas in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: pyarrow>=8.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from datasets) (14.0.2)\nRequirement already satisfied: multiprocess in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: pyarrow-hotfix in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: aiohttp in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from datasets) (3.10.1)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: xxhash in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: contourpy>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (1.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: pyparsing>=2.2.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: fonttools>=4.22.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (4.51.0)\nRequirement already satisfied: joblib>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\nRequirement already satisfied: scipy>=1.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp->datasets) (2.3.5)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->transformers) (1.26.19)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: pytz>=2017.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pandas->datasets) (2022.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1737392677695
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PyTorch version: 2.4.1+cu121\nCUDA available: False\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1737426490370
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "print(\"Scikit-learn está instalado y listo para usar.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Scikit-learn está instalado y listo para usar.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1737426510829
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar librerías necesarias\n",
        "!pip install transformers datasets matplotlib\n",
        "import torch\n",
        "import time\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, TrainerCallback\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (4.36.2)\nRequirement already satisfied: datasets in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (2.16.1)\nRequirement already satisfied: matplotlib in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (3.6.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (0.24.5)\nRequirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: requests in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: tqdm>=4.27 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: safetensors>=0.3.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (3.15.4)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (24.1)\nRequirement already satisfied: regex!=2019.12.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers) (2024.7.24)\nRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from datasets) (2023.10.0)\nRequirement already satisfied: aiohttp in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from datasets) (3.10.1)\nRequirement already satisfied: pyarrow>=8.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from datasets) (14.0.2)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: xxhash in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: pandas in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: pyarrow-hotfix in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: multiprocess in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: contourpy>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (1.2.1)\nRequirement already satisfied: pillow>=6.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (9.2.0)\nRequirement already satisfied: fonttools>=4.22.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (4.51.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp->datasets) (2.3.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.12.2)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->transformers) (1.26.19)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: pytz>=2017.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pandas->datasets) (2022.5)\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  _torch_pytree._register_pytree_node(\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  _torch_pytree._register_pytree_node(\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  _torch_pytree._register_pytree_node(\n2025-01-21 02:29:49.730208: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-01-21 02:29:51.058508: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-01-21 02:29:51.449414: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-01-21 02:29:54.366069: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-01-21 02:30:00.892279: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGZMkCVci539",
        "outputId": "2b430fd3-f96f-40f2-c811-39ec230f56e3",
        "gather": {
          "logged": 1737426598869
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. Deshabilitar WandB\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "id": "83UdwWlFi56q",
        "gather": {
          "logged": 1737426612566
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Cargar el dataset IMDB\n",
        "dataset = load_dataset(\"imdb\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading readme:   0%|          | 0.00/7.81k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "262062c64cdb49f8ac1a067467fbd90d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/21.0M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d59b569b98774c379381ffa22628030c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/20.5M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60b80fdff8074168983b278e803173a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/42.0M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4043e7b77e4640a7b3be2360adc294b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "221b9e109a494065b739c2f5acc2af18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c809ff871cd24be281a08a208b1978d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "307d1a7101164a7aad0108e049ab3985"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "id": "TkKvXCxqi59W",
        "gather": {
          "logged": 1737426619142
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Configurar el tokenizador\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", use_fast=True)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6495e2bd614418aa54b0f308876dd89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8be7c7f943e7420d983f58afa5391e5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e64f6dee0224b4283d4cf40abd80d26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab56cfd758554d58b7a5d755dce60bcc"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "id": "bv-BjBhpi6HY",
        "gather": {
          "logged": 1737426625311
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. Tokenización optimizada\n",
        "tokenized_datasets = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    batch_size=1000,\n",
        "    num_proc=4\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map (num_proc=4):   0%|          | 0/25000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "531d5412b18342eeb219540b02fe3205"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map (num_proc=4):   0%|          | 0/25000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae23c0f61c2c4083997c8d0bbca98886"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map (num_proc=4):   0%|          | 0/50000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0dbb5bbba1e24f09b8de33b6a7e6881d"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "id": "YnyBlmFbi6KF",
        "gather": {
          "logged": 1737426657193
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Preparar el dataset para PyTorch\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "\n",
        "train_dataset = tokenized_datasets[\"train\"]\n",
        "val_dataset = tokenized_datasets[\"test\"]\n"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "id": "R0sqAqa5i6Md",
        "gather": {
          "logged": 1737426662883
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4. Cargar el modelo BERT preentrenado\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a35362c147b84f6e987032e73035003a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiSawWUYi6O_",
        "outputId": "0bc23494-9020-4ec1-e1be-4ae597ca4042",
        "gather": {
          "logged": 1737426671705
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 5. Argumentos de entrenamiento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",               # Carpeta de salida\n",
        "    evaluation_strategy=\"epoch\",         # Evaluar en cada época\n",
        "    logging_dir=\"./logs\",                # Carpeta de logs\n",
        "    logging_steps=50,                    # Frecuencia de registro de métricas\n",
        "    learning_rate=2e-5,                  # Tasa de aprendizaje\n",
        "    per_device_train_batch_size=8,       # Tamaño de lote de entrenamiento\n",
        "    per_device_eval_batch_size=8,        # Tamaño de lote de evaluación\n",
        "    num_train_epochs=1,                  # Número de épocas\n",
        "    weight_decay=0.01,                   # Decaimiento del peso\n",
        "    save_total_limit=2,                  # Guardar máximo 2 checkpoints\n",
        ")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWoGP5OkjDGP",
        "outputId": "4323f051-bf84-4d98-efd6-daaa990ff990",
        "gather": {
          "logged": 1737426811326
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Personalizar el callback para registrar métricas\n",
        "class MetricsLogger(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.logs = {\"train_loss\": [], \"eval_loss\": [], \"epoch\": []}\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is None:\n",
        "            return\n",
        "        # Registrar las métricas\n",
        "        if \"loss\" in logs:\n",
        "            self.logs[\"train_loss\"].append(logs[\"loss\"])\n",
        "        if \"eval_loss\" in logs:\n",
        "            self.logs[\"eval_loss\"].append(logs[\"eval_loss\"])\n",
        "        if \"epoch\" in logs:\n",
        "            self.logs[\"epoch\"].append(logs[\"epoch\"])\n",
        "\n",
        "metrics_logger = MetricsLogger()"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "id": "-E10Xi-QjDBT",
        "gather": {
          "logged": 1737426816052
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para calcular métricas\n",
        "def compute_metrics(pred):\n",
        "    predictions = pred.predictions.argmax(-1)  # Obtener las clases predichas\n",
        "    labels = pred.label_ids                   # Etiquetas reales\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "id": "iUliZ0FUn45H",
        "gather": {
          "logged": 1737426818183
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar el entrenador\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics  # Añadir cálculo de métricas\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "id": "oEVWiIK2jC9-",
        "gather": {
          "logged": 1737426819746
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Entrenar el modelo\n",
        "trainer.train()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2025/01/21 02:33:49 INFO mlflow.tracking._tracking_service.client: 🏃 View run ./results at: https://eastus.api.azureml.ms/mlflow/v2.0/subscriptions/ff6dd32f-ba95-466d-8b04-529c86f648b6/resourceGroups/kenmachinelearning/providers/Microsoft.MachineLearningServices/workspaces/kenbert/#/experiments/741cb9aa-5217-446a-ae51-82fa4e05c45e/runs/f276f2c8-dda8-420f-8e55-884231c957b8.\n2025/01/21 02:33:49 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://eastus.api.azureml.ms/mlflow/v2.0/subscriptions/ff6dd32f-ba95-466d-8b04-529c86f648b6/resourceGroups/kenmachinelearning/providers/Microsoft.MachineLearningServices/workspaces/kenbert/#/experiments/741cb9aa-5217-446a-ae51-82fa4e05c45e.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3125/3125 1:37:59, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.289700</td>\n      <td>0.307914</td>\n      <td>0.886640</td>\n      <td>0.880312</td>\n      <td>0.894960</td>\n      <td>0.887575</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2025/01/21 04:11:50 INFO mlflow.tracking._tracking_service.client: 🏃 View run ./results at: https://eastus.api.azureml.ms/mlflow/v2.0/subscriptions/ff6dd32f-ba95-466d-8b04-529c86f648b6/resourceGroups/kenmachinelearning/providers/Microsoft.MachineLearningServices/workspaces/kenbert/#/experiments/741cb9aa-5217-446a-ae51-82fa4e05c45e/runs/3fcc5af7-c856-4c43-a807-7b326b9dc91b.\n2025/01/21 04:11:50 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://eastus.api.azureml.ms/mlflow/v2.0/subscriptions/ff6dd32f-ba95-466d-8b04-529c86f648b6/resourceGroups/kenmachinelearning/providers/Microsoft.MachineLearningServices/workspaces/kenbert/#/experiments/741cb9aa-5217-446a-ae51-82fa4e05c45e.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "TrainOutput(global_step=3125, training_loss=0.34871707244873046, metrics={'train_runtime': 5880.1166, 'train_samples_per_second': 4.252, 'train_steps_per_second': 0.531, 'total_flos': 1644444096000000.0, 'train_loss': 0.34871707244873046, 'epoch': 1.0})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "zYWr8FsyjC6j",
        "outputId": "b7c902e1-1cea-42cf-9cab-119aa890262b",
        "gather": {
          "logged": 1737432703748
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo entrenado\n",
        "output_dir = \"./imdb_bert_model\"\n",
        "trainer.save_model(output_dir)\n",
        "\n",
        "# Guardar el tokenizador asociado al modelo\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"Modelo y tokenizador guardados en: {output_dir}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Modelo y tokenizador guardados en: ./imdb_bert_model\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtWbLq4Xl4Mk",
        "outputId": "258a0205-9606-421f-dfa3-bfb5f4f4840f",
        "gather": {
          "logged": 1737432787882
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluar el modelo en el conjunto de validación\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "# Mostrar las métricas de evaluación\n",
        "print(\"Resultados de la evaluación:\")\n",
        "for key, value in eval_results.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "# Tamaño del modelo en MB\n",
        "model_size = sum(p.numel() for p in model.parameters()) * 4 / (1024 ** 2)  # 4 bytes por float32\n",
        "\n",
        "# Número de parámetros entrenables\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3125/3125 19:27]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Resultados de la evaluación:\neval_loss: 0.3079136610031128\neval_accuracy: 0.88664\neval_precision: 0.8803116147308782\neval_recall: 0.89496\neval_f1: 0.8875753728974929\neval_runtime: 1167.8566\neval_samples_per_second: 21.407\neval_steps_per_second: 2.676\nepoch: 1.0\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "XdOFAo3moT-t",
        "outputId": "2b31e243-502b-45cd-e675-7462753acd6c",
        "gather": {
          "logged": 1737434082179
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Ruta donde guardaste el modelo\n",
        "output_dir = \"./imdb_bert_model\"\n",
        "\n",
        "# Cargar el modelo y el tokenizador\n",
        "model = AutoModelForSequenceClassification.from_pretrained(output_dir)  # Cargar modelo\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir)  # Cargar el tokenizador\n",
        "\n",
        "# Configurar el dispositivo (CPU)\n",
        "device = torch.device(\"cpu\")\n",
        "model.to(device)  # Asegurarse de que el modelo esté en CPU\n",
        "\n",
        "# Texto de prueba\n",
        "text = \"This movie was absolutely horrible! I loved every moment of it.\"\n",
        "\n",
        "# Tokenizar el texto de prueba\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "\n",
        "# Asegurar que los datos también estén en CPU\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "# Medir el tiempo de inferencia\n",
        "model.eval()  # Cambiar el modelo a modo de evaluación\n",
        "start_time = time.time()  # Iniciar medición de tiempo\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "end_time = time.time()  # Finalizar medición de tiempo\n",
        "\n",
        "# Calcular el tiempo de inferencia\n",
        "inference_time = (end_time - start_time) * 1000  # Tiempo en milisegundos\n",
        "\n",
        "# Obtener la clase predicha\n",
        "predicted_class = torch.argmax(outputs.logits, dim=-1).item()\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(f\"Predicción: {'Positivo' if predicted_class == 1 else 'Negativo'}\")\n",
        "print(f\"Tiempo de inferencia en CPU: {inference_time:.2f} ms\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Predicción: Negativo\nTiempo de inferencia en CPU: 35.17 ms\n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1737434467153
        }
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "es"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}